{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "149YZvN5dr0jf5ScmwJB9WDkpoS_Smi27",
      "authorship_tag": "ABX9TyOb1HHh9gZ1nh3Tgno1XSo0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarouenKadri/Algorithmic-Thinking/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "--N22_0tEuG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3260c0-4ed5-4946-a6b9-d39d14199eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "8_ASUKZeSZPu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "tJsXRhO0SXLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c715620d-e3d0-4a1c-c83a-af2f8cd73373"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZGIv7G6cTw",
        "outputId": "e032260f-2610-4544-a643-f42028ce1329"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 19 19:41:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W /  70W |    339MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, \\\n",
        "    Dropout, Lambda,LeakyReLU ,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "\n",
        "################################################################\n",
        "# Load Data\n",
        "################################################################\n",
        "train_dir1 =\"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/dataset/img/train\"\n",
        "train_dir2 =\"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/dataset/test/train\"\n",
        "test_dir= \"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/dataset/GRD/train\"\n",
        "print('total training img :',len(os.listdir(train_dir1)))\n",
        "print('total testing data :', len(os.listdir(test_dir))  )\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "X_train1=[]\n",
        "X_train2=[]\n",
        "Y_train=[]\n",
        "##########################################################################################\n",
        "image_files1 = [f for f in os.listdir(train_dir1) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "sorted_files1 = sorted(image_files1)\n",
        "\n",
        "for filename in sorted_files1:\n",
        "    img=cv2.imread(os.path.join(train_dir1,filename))\n",
        "    X_train1.append(img/255.0)\n",
        "X_train1=np.array(X_train1)  \n",
        "########################################################################################\n",
        "image_files2 = [f for f in os.listdir(train_dir2) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "sorted_files2 = sorted(image_files2)\n",
        "for filename in sorted_files2:\n",
        "    img=cv2.imread(os.path.join(train_dir2,filename),cv2.IMREAD_GRAYSCALE)\n",
        "    X_train2.append(img/255.0)\n",
        "X_train2=np.array(X_train2)\n",
        "########################################################################################\n",
        "image_files3 = [f for f in os.listdir(test_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "sorted_files3 = sorted(image_files3)\n",
        "for filename in sorted_files3:\n",
        "    img=cv2.imread(os.path.join(test_dir,filename),cv2.IMREAD_GRAYSCALE)\n",
        "    Y_train.append(img/255.0)\n",
        "Y_train=np.array(Y_train)\n",
        "\n",
        "print(Y_train.shape)\n",
        "print(X_train2.shape)\n",
        "print(X_train1.shape)\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + smooth) / (K.sum(y_true_f*y_true_f) + K.sum(y_pred_f*y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "def DoubleConv(input_tensor, n_filters, kernel_size=3):\n",
        "        X = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), padding='same',\n",
        "                   kernel_initializer='he_normal')(input_tensor)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = LeakyReLU(alpha=0.1)(X)\n",
        "        x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), padding='same',\n",
        "                   kernel_initializer='he_normal')(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = LeakyReLU(alpha=0.1)(X)\n",
        "        return X\n",
        "\n",
        "def Unet_model() :\n",
        "    IMG_WIDTH = 640\n",
        "    IMG_HEIGHT = 640\n",
        "    IMG_CHANNELS1 = 3\n",
        "    IMG_CHANNELS2 = 1\n",
        "    input1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS1))\n",
        "    input2 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS2))\n",
        "    input1 = Lambda(lambda x: x / 255)(input1)\n",
        "    input2= Lambda(lambda x: x / 255)(input2)\n",
        "\n",
        "    input_tensor = concatenate([input1, input2])\n",
        "    #########################################################################################################################################\n",
        "    c1=DoubleConv(input_tensor, 64, kernel_size=3)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)  \n",
        "    p1 = Dropout(0.1)(p1)\n",
        "    ############################################################################################################################################\n",
        "    c2=DoubleConv(p1, 128, kernel_size=3)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    #############################################################################################################################################\n",
        "    c3 = DoubleConv(p2, 256, kernel_size=3)\n",
        "    p3=MaxPooling2D ((2,2))(c3)\n",
        "    p3 = Dropout(0.1)(p3)\n",
        "    ###############################################################################################################################################\n",
        "    c4 = DoubleConv(p3, 512, kernel_size=3)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    #################################################################################################################################################\n",
        "    c5 = DoubleConv(p4, 512, kernel_size=3)  \n",
        "    c5 = Dropout(0.1)(c5)\n",
        "    ################################################################################################################################################\n",
        "    # Expansive path\n",
        "    concate1 = Conv2DTranspose(1024, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    concate1 = concatenate([concate1, c4])\n",
        "    u1 = DoubleConv(concate1, 256, kernel_size=3)\n",
        "    #################################################################################################################################################\n",
        "    # 2nd Upsampling & concatenate\n",
        "    concate2 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(u1)\n",
        "    concate2= concatenate([concate2,c3])\n",
        "    # 3rd Conv2D layer\n",
        "    u2 = DoubleConv(concate2, 128, kernel_size=3)\n",
        "    u2 = Dropout(0.1)(u2)\n",
        "    ################################################################################################################################################\n",
        "    # 4th Upsampling & concatenate\n",
        "    concate3 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(u2)\n",
        "    concate3 = concatenate([concate3, c2])\n",
        "    u3 = DoubleConv(concate3, 64, kernel_size=3)\n",
        "    u3 = Dropout(0.1)(u3)\n",
        "    ##################################################################################################################################################\n",
        "    # 5th Upsampling & concatenate\n",
        "    concate4 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(u3)\n",
        "    concate4 = concatenate([concate4, c1])\n",
        "    u4 = DoubleConv(concate4, 64, kernel_size=3)\n",
        "    ##################################################################################################################################################\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(u4)\n",
        "\n",
        "    model = Model(inputs=[input1,input2], outputs=[outputs])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model=Unet_model()\n",
        "    model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coefficient])\n",
        "    model.summary()\n",
        "    model.fit([X_train1, X_train2], Y_train, epochs=20, batch_size=4)\n",
        "    model.save('model.h5')\n",
        "    print('done !')"
      ],
      "metadata": {
        "id": "BWhymAwzLuHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3596c5-91a7-48e2-b6fa-f5d407b98b74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training img : 85\n",
            "total testing data : 85\n",
            "(85, 640, 640)\n",
            "(85, 640, 640)\n",
            "(85, 640, 640, 3)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 640, 640, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 640, 640, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 640, 640, 4)  0           ['input_3[0][0]',                \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 640, 640, 64  2368        ['concatenate[1][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 640, 640, 64  256        ['conv2d[1][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 640, 640, 64  0           ['batch_normalization[1][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 640, 640, 64  256        ['leaky_re_lu[1][0]']            \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 640, 640, 64  0           ['batch_normalization_1[1][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 320, 320, 64  0           ['leaky_re_lu_1[1][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 320, 320, 64  0           ['max_pooling2d[1][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 320, 320, 12  73856       ['dropout[1][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 320, 320, 12  512        ['conv2d_2[1][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 320, 320, 12  0           ['batch_normalization_2[1][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 320, 320, 12  512        ['leaky_re_lu_2[1][0]']          \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 320, 320, 12  0           ['batch_normalization_3[1][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 160, 160, 12  0          ['leaky_re_lu_3[1][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 160, 160, 25  295168      ['max_pooling2d_1[1][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 160, 160, 25  1024       ['conv2d_4[1][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 160, 160, 25  0           ['batch_normalization_4[1][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 160, 160, 25  1024       ['leaky_re_lu_4[1][0]']          \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 160, 160, 25  0           ['batch_normalization_5[1][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 80, 80, 256)  0          ['leaky_re_lu_5[1][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 80, 80, 256)  0           ['max_pooling2d_2[1][0]']        \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 80, 80, 512)  1180160     ['dropout_1[1][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 80, 80, 512)  2048       ['conv2d_6[1][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 80, 80, 512)  0           ['batch_normalization_6[1][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 80, 80, 512)  2048       ['leaky_re_lu_6[1][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 80, 80, 512)  0           ['batch_normalization_7[1][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 40, 40, 512)  0          ['leaky_re_lu_7[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 40, 40, 512)  2359808     ['max_pooling2d_3[1][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 40, 40, 512)  2048       ['conv2d_8[1][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 40, 40, 512)  0           ['batch_normalization_8[1][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 40, 40, 512)  2048       ['leaky_re_lu_8[1][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 40, 40, 512)  0           ['batch_normalization_9[1][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 40, 40, 512)  0           ['leaky_re_lu_9[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 80, 80, 1024  2098176    ['dropout_2[1][0]']              \n",
            " ose)                           )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 80, 80, 1536  0           ['conv2d_transpose[1][0]',       \n",
            "                                )                                 'leaky_re_lu_7[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 80, 80, 256)  3539200     ['concatenate_1[1][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 80, 80, 256)  1024       ['conv2d_10[1][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 80, 80, 256)  0           ['batch_normalization_10[1][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 80, 80, 256)  1024       ['leaky_re_lu_10[1][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 80, 80, 256)  0           ['batch_normalization_11[1][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 160, 160, 51  524800     ['leaky_re_lu_11[1][0]']         \n",
            " spose)                         2)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 160, 160, 76  0           ['conv2d_transpose_1[1][0]',     \n",
            "                                8)                                'leaky_re_lu_5[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 160, 160, 12  884864      ['concatenate_2[1][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 160, 160, 12  512        ['conv2d_12[1][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 160, 160, 12  0           ['batch_normalization_12[1][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 160, 160, 12  512        ['leaky_re_lu_12[1][0]']         \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)     (None, 160, 160, 12  0           ['batch_normalization_13[1][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 160, 160, 12  0           ['leaky_re_lu_13[1][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 320, 320, 25  131328     ['dropout_3[1][0]']              \n",
            " spose)                         6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 320, 320, 38  0           ['conv2d_transpose_2[1][0]',     \n",
            "                                4)                                'leaky_re_lu_3[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 320, 320, 64  221248      ['concatenate_3[1][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 320, 320, 64  256        ['conv2d_14[1][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_14 (LeakyReLU)     (None, 320, 320, 64  0           ['batch_normalization_14[1][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 320, 320, 64  256        ['leaky_re_lu_14[1][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_15 (LeakyReLU)     (None, 320, 320, 64  0           ['batch_normalization_15[1][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 320, 320, 64  0           ['leaky_re_lu_15[1][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 640, 640, 12  32896      ['dropout_4[1][0]']              \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 640, 640, 19  0           ['conv2d_transpose_3[1][0]',     \n",
            "                                2)                                'leaky_re_lu_1[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 640, 640, 64  110656      ['concatenate_4[1][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 640, 640, 64  256        ['conv2d_16[1][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_16 (LeakyReLU)     (None, 640, 640, 64  0           ['batch_normalization_16[1][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 640, 640, 64  256        ['leaky_re_lu_16[1][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_17 (LeakyReLU)     (None, 640, 640, 64  0           ['batch_normalization_17[1][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 640, 640, 1)  65          ['leaky_re_lu_17[1][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,470,465\n",
            "Trainable params: 11,462,529\n",
            "Non-trainable params: 7,936\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "22/22 [==============================] - 70s 2s/step - loss: 0.8017 - dice_coefficient: 0.2059\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 32s 1s/step - loss: 0.6572 - dice_coefficient: 0.3316\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 32s 1s/step - loss: 0.5604 - dice_coefficient: 0.4476\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 33s 1s/step - loss: 0.5277 - dice_coefficient: 0.4811\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 33s 1s/step - loss: 0.4396 - dice_coefficient: 0.5522\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 33s 1s/step - loss: 0.4178 - dice_coefficient: 0.5868\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3869 - dice_coefficient: 0.6192\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3732 - dice_coefficient: 0.6180\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3611 - dice_coefficient: 0.6363\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3253 - dice_coefficient: 0.6651\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3501 - dice_coefficient: 0.6551\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3549 - dice_coefficient: 0.6280\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3763 - dice_coefficient: 0.6286\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3424 - dice_coefficient: 0.6352\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3031 - dice_coefficient: 0.6732\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.2965 - dice_coefficient: 0.7012\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3041 - dice_coefficient: 0.6888\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3132 - dice_coefficient: 0.6891\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.2779 - dice_coefficient: 0.7281\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 33s 2s/step - loss: 0.3040 - dice_coefficient: 0.6780\n",
            "done !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  \n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import cv2\n",
        "import keras.models\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, \\\n",
        "    Dropout, Lambda,LeakyReLU ,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K  \n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "test_dir1 =\"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/dataset/img/test\"\n",
        "test_dir2 =\"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/dataset/test/test\"\n",
        "\n",
        "print('total training img :',len(os.listdir(test_dir1)))\n",
        "print('total testing data :', len(os.listdir(test_dir2))  )\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + smooth) / (K.sum(y_true_f*y_true_f) + K.sum(y_pred_f*y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "Y_test1=[]\n",
        "Y_test2=[]\n",
        "\n",
        "image_files1 = [f for f in os.listdir(test_dir1) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "sorted_files1 = sorted(image_files1)\n",
        "\n",
        "for filename in sorted_files1:\n",
        "    img=cv2.imread(os.path.join(test_dir1,filename))\n",
        "    Y_test1.append(img/255.0)\n",
        "Y_test1=np.array(Y_test1)\n",
        "Y_test1 = Y_test1 \n",
        "\n",
        "\n",
        "image_files2 = [f for f in os.listdir(test_dir2) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "sorted_files2 = sorted(image_files2)\n",
        "for filename in sorted_files2:\n",
        "    img=cv2.imread(os.path.join(test_dir2,filename),cv2.IMREAD_GRAYSCALE)\n",
        "    Y_test2.append(img/255.0)\n",
        "Y_test2=np.array(Y_test2)\n",
        "Y_test2 = Y_test2 \n",
        "\n",
        "#import the model\n",
        "model = keras.models.load_model('/content/model.h5',custom_objects={'dice_loss': dice_loss, 'dice_coefficient': dice_coefficient} )\n",
        "predicted_masks = model.predict([Y_test1,Y_test2],batch_size=4)\n",
        "\n",
        "threshold = 0.5\n",
        "predicted_masks = (predicted_masks > threshold).astype('uint8')\n",
        "print(predicted_masks.shape)\n",
        "for i in range(predicted_masks.shape[0]):\n",
        "         print(predicted_masks[i]*255)  \n",
        "\n",
        "         cv2.imwrite('bbbb{}.png'.format(i), predicted_masks[i]*255)\n",
        "\n",
        "print('Done !')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsBXT9S0ehTC",
        "outputId": "dc779849-1b75-456a-d2fe-0e1d8551bdc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training img : 31\n",
            "total testing data : 31\n",
            "8/8 [==============================] - 9s 1s/step\n",
            "(31, 640, 640, 1)\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "[[[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]\n",
            "\n",
            " [[0]\n",
            "  [0]\n",
            "  [0]\n",
            "  ...\n",
            "  [0]\n",
            "  [0]\n",
            "  [0]]]\n",
            "Done !\n"
          ]
        }
      ]
    }
  ]
}