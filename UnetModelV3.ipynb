{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/MarouenKadri/Algorithmic-Thinking/blob/main/Untitled13.ipynb",
      "authorship_tag": "ABX9TyPHGymqWW4AN/SUjzzDcqRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarouenKadri/Algorithmic-Thinking/blob/main/UnetModelV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "--N22_0tEuG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149be046-3025-4d1b-fc21-ec4edbb868e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "8_ASUKZeSZPu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "tJsXRhO0SXLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ad0df2-0e5b-4d90-fabd-8ef587551592"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZGIv7G6cTw",
        "outputId": "96a02f76-b1fd-4d6b-d680-46c40d76e3d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 28 14:43:36 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    31W /  70W |  14541MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataManager :  \n",
        "   def __init__(self) :\n",
        "        self.train_dir1 =\"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/after processing/imgmasked/train\"\n",
        "        self.train_dir2 =\"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/after processing/texture/train\"\n",
        "        self.test_dir= \"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/after processing/grd/train\"\n",
        "        self.load_data()   \n",
        "   def load_data(self):  \n",
        "        X_train1=[]\n",
        "        X_train2=[]\n",
        "        Y_train=[]\n",
        "#load Image as rgb \n",
        "        image_files1 = [f for f in os.listdir(self.train_dir1) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        sorted_files1 = sorted(image_files1)\n",
        "        for filename in sorted_files1:\n",
        "              img=cv2.imread(os.path.join(self.train_dir1,filename))\n",
        "              X_train1.append(img/255.0)\n",
        "        X_train1=np.array(X_train1)  \n",
        "#load image as grayscale\n",
        "        image_files2 = [f for f in os.listdir(self.train_dir2) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        sorted_files2 = sorted(image_files2)\n",
        "        for filename in sorted_files2:\n",
        "              img=cv2.imread(os.path.join(self.train_dir2,filename),cv2.IMREAD_GRAYSCALE)\n",
        "              X_train2.append(img/255.0)\n",
        "        X_train2=np.array(X_train2)\n",
        "#load image as grayscale\n",
        "        image_files3 = [f for f in os.listdir(self.test_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        sorted_files3 = sorted(image_files3)\n",
        "        for filename in sorted_files3:\n",
        "              img=cv2.imread(os.path.join(self.test_dir,filename),cv2.IMREAD_GRAYSCALE)\n",
        "              Y_train.append(img/255.0)\n",
        "        Y_train=np.array(Y_train)  \n",
        "        return X_train1,X_train2,Y_train\n",
        "     \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "axr9CdJYXqkt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, \\\n",
        "    Dropout, Lambda,LeakyReLU ,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import math\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "\n",
        "################################################################\n",
        "# Load Data\n",
        "################################################################\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.20, random_state = 0)\n",
        "\n",
        "manager=DataManager()\n",
        "X_train1 ,X_train2,Y_train=manager.load_data()\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath='best_w.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "lr_max = 0.001\n",
        "lr_min = 0.0001\n",
        "epochs = 40\n",
        "def cosine_annealing(epoch):\n",
        "    cos_inner = (math.pi * epoch) / epochs\n",
        "    return lr_min + 0.5 * (lr_max - lr_min) * (1 + math.cos(cos_inner))\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + smooth) / (K.sum(y_true_f*y_true_f) + K.sum(y_pred_f*y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "def DoubleConv(input_tensor, n_filters, kernel_size=3):\n",
        "        X = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), padding='same',\n",
        "                   kernel_initializer='he_normal')(input_tensor)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = LeakyReLU(alpha=0.1)(X)\n",
        "        x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), padding='same',\n",
        "                   kernel_initializer='he_normal')(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = LeakyReLU(alpha=0.1)(X)\n",
        "        return X\n",
        "\n",
        "def Unet_model() :\n",
        "    IMG_WIDTH = 640\n",
        "    IMG_HEIGHT = 640\n",
        "    IMG_CHANNELS1 = 3\n",
        "    IMG_CHANNELS2 = 1\n",
        "    input1 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS1))\n",
        "    input2 = Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS2))\n",
        "    input1 = Lambda(lambda x: x / 255)(input1)\n",
        "    input2= Lambda(lambda x: x / 255)(input2)\n",
        "\n",
        "    input_tensor = concatenate([input1, input2])\n",
        "    #########################################################################################################################################\n",
        "    c1=DoubleConv(input_tensor, 64, kernel_size=3)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)  \n",
        "    p1 = Dropout(0.1)(p1)\n",
        "    ############################################################################################################################################\n",
        "    c2=DoubleConv(p1, 128, kernel_size=3)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    #############################################################################################################################################\n",
        "    c3 = DoubleConv(p2, 256, kernel_size=3)\n",
        "    p3=MaxPooling2D ((2,2))(c3)\n",
        "    p3 = Dropout(0.1)(p3)\n",
        "    ###############################################################################################################################################\n",
        "    c4 = DoubleConv(p3, 512, kernel_size=3)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    #################################################################################################################################################\n",
        "    c5 = DoubleConv(p4, 512, kernel_size=3)  \n",
        "    c5 = Dropout(0.1)(c5)\n",
        "    ################################################################################################################################################\n",
        "    # Expansive path\n",
        "    concate1 = Conv2DTranspose(1024, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    concate1 = concatenate([concate1, c4])\n",
        "    u1 = DoubleConv(concate1, 256, kernel_size=3)\n",
        "    #################################################################################################################################################\n",
        "    # 2nd Upsampling & concatenate\n",
        "    concate2 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(u1)\n",
        "    concate2= concatenate([concate2,c3])\n",
        "    # 3rd Conv2D layer\n",
        "    u2 = DoubleConv(concate2, 128, kernel_size=3)\n",
        "    u2 = Dropout(0.1)(u2)\n",
        "    ################################################################################################################################################\n",
        "    # 4th Upsampling & concatenate\n",
        "    concate3 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(u2)\n",
        "    concate3 = concatenate([concate3, c2])\n",
        "    u3 = DoubleConv(concate3, 64, kernel_size=3)\n",
        "    u3 = Dropout(0.1)(u3)\n",
        "    ##################################################################################################################################################\n",
        "    # 5th Upsampling & concatenate\n",
        "    concate4 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(u3)\n",
        "    concate4 = concatenate([concate4, c1])\n",
        "    u4 = DoubleConv(concate4, 64, kernel_size=3)\n",
        "    ##################################################################################################################################################\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(u4)\n",
        "\n",
        "    model = Model(inputs=[input1,input2], outputs=[outputs])\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model=Unet_model()\n",
        "    lr_scheduler = LearningRateScheduler(cosine_annealing)\n",
        "    model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coefficient])\n",
        "    model.summary()\n",
        "    model.fit([X_train1, X_train2], Y_train, epochs=40,validation_split=0.2,callbacks=[lr_scheduler,checkpoint], batch_size=4)\n",
        "\n",
        "    model.save('model.h5')\n",
        "    print('done !')"
      ],
      "metadata": {
        "id": "BWhymAwzLuHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8856c83c-8787-4a5f-c497-12ac6bd6dd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 640, 640, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 640, 640, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 640, 640, 4)  0           ['input_3[0][0]',                \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 640, 640, 64  2368        ['concatenate[1][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 640, 640, 64  256        ['conv2d[1][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 640, 640, 64  0           ['batch_normalization[1][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 640, 640, 64  256        ['leaky_re_lu[1][0]']            \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 640, 640, 64  0           ['batch_normalization_1[1][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 320, 320, 64  0           ['leaky_re_lu_1[1][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 320, 320, 64  0           ['max_pooling2d[1][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 320, 320, 12  73856       ['dropout[1][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 320, 320, 12  512        ['conv2d_2[1][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 320, 320, 12  0           ['batch_normalization_2[1][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 320, 320, 12  512        ['leaky_re_lu_2[1][0]']          \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 320, 320, 12  0           ['batch_normalization_3[1][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 160, 160, 12  0          ['leaky_re_lu_3[1][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 160, 160, 25  295168      ['max_pooling2d_1[1][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 160, 160, 25  1024       ['conv2d_4[1][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 160, 160, 25  0           ['batch_normalization_4[1][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 160, 160, 25  1024       ['leaky_re_lu_4[1][0]']          \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 160, 160, 25  0           ['batch_normalization_5[1][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 80, 80, 256)  0          ['leaky_re_lu_5[1][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 80, 80, 256)  0           ['max_pooling2d_2[1][0]']        \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 80, 80, 512)  1180160     ['dropout_1[1][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 80, 80, 512)  2048       ['conv2d_6[1][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 80, 80, 512)  0           ['batch_normalization_6[1][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 80, 80, 512)  2048       ['leaky_re_lu_6[1][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 80, 80, 512)  0           ['batch_normalization_7[1][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 40, 40, 512)  0          ['leaky_re_lu_7[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 40, 40, 512)  2359808     ['max_pooling2d_3[1][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 40, 40, 512)  2048       ['conv2d_8[1][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 40, 40, 512)  0           ['batch_normalization_8[1][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 40, 40, 512)  2048       ['leaky_re_lu_8[1][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 40, 40, 512)  0           ['batch_normalization_9[1][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 40, 40, 512)  0           ['leaky_re_lu_9[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 80, 80, 1024  2098176    ['dropout_2[1][0]']              \n",
            " ose)                           )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 80, 80, 1536  0           ['conv2d_transpose[1][0]',       \n",
            "                                )                                 'leaky_re_lu_7[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 80, 80, 256)  3539200     ['concatenate_1[1][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 80, 80, 256)  1024       ['conv2d_10[1][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 80, 80, 256)  0           ['batch_normalization_10[1][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 80, 80, 256)  1024       ['leaky_re_lu_10[1][0]']         \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 80, 80, 256)  0           ['batch_normalization_11[1][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 160, 160, 51  524800     ['leaky_re_lu_11[1][0]']         \n",
            " spose)                         2)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 160, 160, 76  0           ['conv2d_transpose_1[1][0]',     \n",
            "                                8)                                'leaky_re_lu_5[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 160, 160, 12  884864      ['concatenate_2[1][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 160, 160, 12  512        ['conv2d_12[1][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 160, 160, 12  0           ['batch_normalization_12[1][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 160, 160, 12  512        ['leaky_re_lu_12[1][0]']         \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)     (None, 160, 160, 12  0           ['batch_normalization_13[1][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 160, 160, 12  0           ['leaky_re_lu_13[1][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 320, 320, 25  131328     ['dropout_3[1][0]']              \n",
            " spose)                         6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 320, 320, 38  0           ['conv2d_transpose_2[1][0]',     \n",
            "                                4)                                'leaky_re_lu_3[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 320, 320, 64  221248      ['concatenate_3[1][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 320, 320, 64  256        ['conv2d_14[1][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_14 (LeakyReLU)     (None, 320, 320, 64  0           ['batch_normalization_14[1][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 320, 320, 64  256        ['leaky_re_lu_14[1][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_15 (LeakyReLU)     (None, 320, 320, 64  0           ['batch_normalization_15[1][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 320, 320, 64  0           ['leaky_re_lu_15[1][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 640, 640, 12  32896      ['dropout_4[1][0]']              \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 640, 640, 19  0           ['conv2d_transpose_3[1][0]',     \n",
            "                                2)                                'leaky_re_lu_1[1][0]']          \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 640, 640, 64  110656      ['concatenate_4[1][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 640, 640, 64  256        ['conv2d_16[1][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_16 (LeakyReLU)     (None, 640, 640, 64  0           ['batch_normalization_16[1][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 640, 640, 64  256        ['leaky_re_lu_16[1][0]']         \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_17 (LeakyReLU)     (None, 640, 640, 64  0           ['batch_normalization_17[1][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 640, 640, 1)  65          ['leaky_re_lu_17[1][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,470,465\n",
            "Trainable params: 11,462,529\n",
            "Non-trainable params: 7,936\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.5913 - dice_coefficient: 0.4087\n",
            "Epoch 1: val_loss improved from inf to 0.94918, saving model to best_w.h5\n",
            "58/58 [==============================] - 138s 2s/step - loss: 0.5913 - dice_coefficient: 0.4087 - val_loss: 0.9492 - val_dice_coefficient: 0.0500 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3303 - dice_coefficient: 0.6697\n",
            "Epoch 2: val_loss did not improve from 0.94918\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.3303 - dice_coefficient: 0.6697 - val_loss: 0.9737 - val_dice_coefficient: 0.0259 - lr: 9.9861e-04\n",
            "Epoch 3/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.3230 - dice_coefficient: 0.6770\n",
            "Epoch 3: val_loss did not improve from 0.94918\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.3230 - dice_coefficient: 0.6770 - val_loss: 0.9796 - val_dice_coefficient: 0.0201 - lr: 9.9446e-04\n",
            "Epoch 4/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2854 - dice_coefficient: 0.7146\n",
            "Epoch 4: val_loss improved from 0.94918 to 0.92599, saving model to best_w.h5\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2854 - dice_coefficient: 0.7146 - val_loss: 0.9260 - val_dice_coefficient: 0.0728 - lr: 9.8757e-04\n",
            "Epoch 5/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2718 - dice_coefficient: 0.7282\n",
            "Epoch 5: val_loss improved from 0.92599 to 0.82107, saving model to best_w.h5\n",
            "58/58 [==============================] - 99s 2s/step - loss: 0.2718 - dice_coefficient: 0.7282 - val_loss: 0.8211 - val_dice_coefficient: 0.1760 - lr: 9.7798e-04\n",
            "Epoch 6/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2586 - dice_coefficient: 0.7414\n",
            "Epoch 6: val_loss improved from 0.82107 to 0.53014, saving model to best_w.h5\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2586 - dice_coefficient: 0.7414 - val_loss: 0.5301 - val_dice_coefficient: 0.4623 - lr: 9.6575e-04\n",
            "Epoch 7/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2526 - dice_coefficient: 0.7474\n",
            "Epoch 7: val_loss did not improve from 0.53014\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2526 - dice_coefficient: 0.7474 - val_loss: 0.5334 - val_dice_coefficient: 0.4593 - lr: 9.5095e-04\n",
            "Epoch 8/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2522 - dice_coefficient: 0.7478\n",
            "Epoch 8: val_loss did not improve from 0.53014\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2522 - dice_coefficient: 0.7478 - val_loss: 0.6597 - val_dice_coefficient: 0.3350 - lr: 9.3369e-04\n",
            "Epoch 9/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2345 - dice_coefficient: 0.7655\n",
            "Epoch 9: val_loss did not improve from 0.53014\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2345 - dice_coefficient: 0.7655 - val_loss: 0.6127 - val_dice_coefficient: 0.3812 - lr: 9.1406e-04\n",
            "Epoch 10/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2387 - dice_coefficient: 0.7613\n",
            "Epoch 10: val_loss improved from 0.53014 to 0.42362, saving model to best_w.h5\n",
            "58/58 [==============================] - 99s 2s/step - loss: 0.2387 - dice_coefficient: 0.7613 - val_loss: 0.4236 - val_dice_coefficient: 0.5672 - lr: 8.9218e-04\n",
            "Epoch 11/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2350 - dice_coefficient: 0.7650\n",
            "Epoch 11: val_loss improved from 0.42362 to 0.34266, saving model to best_w.h5\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2350 - dice_coefficient: 0.7650 - val_loss: 0.3427 - val_dice_coefficient: 0.6475 - lr: 8.6820e-04\n",
            "Epoch 12/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2230 - dice_coefficient: 0.7770\n",
            "Epoch 12: val_loss did not improve from 0.34266\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2230 - dice_coefficient: 0.7770 - val_loss: 0.3778 - val_dice_coefficient: 0.6129 - lr: 8.4225e-04\n",
            "Epoch 13/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2267 - dice_coefficient: 0.7733\n",
            "Epoch 13: val_loss improved from 0.34266 to 0.31309, saving model to best_w.h5\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2267 - dice_coefficient: 0.7733 - val_loss: 0.3131 - val_dice_coefficient: 0.6764 - lr: 8.1450e-04\n",
            "Epoch 14/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2058 - dice_coefficient: 0.7942\n",
            "Epoch 14: val_loss did not improve from 0.31309\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2058 - dice_coefficient: 0.7942 - val_loss: 0.4601 - val_dice_coefficient: 0.5313 - lr: 7.8512e-04\n",
            "Epoch 15/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.1894 - dice_coefficient: 0.8106\n",
            "Epoch 15: val_loss improved from 0.31309 to 0.28770, saving model to best_w.h5\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.1894 - dice_coefficient: 0.8106 - val_loss: 0.2877 - val_dice_coefficient: 0.7017 - lr: 7.5430e-04\n",
            "Epoch 16/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.2047 - dice_coefficient: 0.7953\n",
            "Epoch 16: val_loss did not improve from 0.28770\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.2047 - dice_coefficient: 0.7953 - val_loss: 0.4501 - val_dice_coefficient: 0.5417 - lr: 7.2221e-04\n",
            "Epoch 17/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.1826 - dice_coefficient: 0.8174\n",
            "Epoch 17: val_loss did not improve from 0.28770\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.1826 - dice_coefficient: 0.8174 - val_loss: 0.3125 - val_dice_coefficient: 0.6771 - lr: 6.8906e-04\n",
            "Epoch 18/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.1845 - dice_coefficient: 0.8155\n",
            "Epoch 18: val_loss did not improve from 0.28770\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.1845 - dice_coefficient: 0.8155 - val_loss: 0.3432 - val_dice_coefficient: 0.6463 - lr: 6.5505e-04\n",
            "Epoch 19/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.1751 - dice_coefficient: 0.8249\n",
            "Epoch 19: val_loss did not improve from 0.28770\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.1751 - dice_coefficient: 0.8249 - val_loss: 0.3286 - val_dice_coefficient: 0.6604 - lr: 6.2040e-04\n",
            "Epoch 20/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.1553 - dice_coefficient: 0.8447\n",
            "Epoch 20: val_loss did not improve from 0.28770\n",
            "58/58 [==============================] - 98s 2s/step - loss: 0.1553 - dice_coefficient: 0.8447 - val_loss: 0.3207 - val_dice_coefficient: 0.6683 - lr: 5.8531e-04\n",
            "Epoch 21/40\n",
            "58/58 [==============================] - ETA: 0s - loss: 0.1664 - dice_coefficient: 0.8336\n",
            "Epoch 21: val_loss improved from 0.28770 to 0.27058, saving model to best_w.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  \n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import cv2\n",
        "import keras.models\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, \\\n",
        "    Dropout, Lambda,LeakyReLU ,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "import keras.backend as K  \n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "test_dir1 =\"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/dataset/img/test\"\n",
        "test_dir2 =\"/content/drive/MyDrive/Colab Notebooks/WrinkleDetection_Unet/dataset/test/test\"\n",
        "\n",
        "print('total training img :',len(os.listdir(test_dir1)))\n",
        "print('total testing data :', len(os.listdir(test_dir2))  )\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(K.cast(y_true, 'float32'))\n",
        "    y_pred_f = K.flatten(K.cast(y_pred, 'float32'))\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + smooth) / (K.sum(y_true_f*y_true_f) + K.sum(y_pred_f*y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "Y_test1=[]\n",
        "Y_test2=[]\n",
        "\n",
        "image_files1 = [f for f in os.listdir(test_dir1) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "sorted_files1 = sorted(image_files1)\n",
        "\n",
        "for filename in sorted_files1:\n",
        "    img=cv2.imread(os.path.join(test_dir1,filename))\n",
        "    Y_test1.append(img/255.0)\n",
        "Y_test1=np.array(Y_test1)\n",
        "Y_test1 = Y_test1 \n",
        "\n",
        "\n",
        "image_files2 = [f for f in os.listdir(test_dir2) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "sorted_files2 = sorted(image_files2)\n",
        "for filename in sorted_files2:\n",
        "    img=cv2.imread(os.path.join(test_dir2,filename),cv2.IMREAD_GRAYSCALE)\n",
        "    Y_test2.append(img/255.0)\n",
        "Y_test2=np.array(Y_test2)\n",
        "Y_test2 = Y_test2 \n",
        "\n",
        "#import the model\n",
        "model = keras.models.load_model('/content/best_weights.h5')\n",
        "#model = keras.models.load_model('/content/best_weights.h5',custom_objects={'dice_loss': dice_loss, 'dice_coefficient': dice_coefficient} )\n",
        "predicted_masks = model.predict([Y_test1,Y_test2],batch_size=4)\n",
        "\n",
        "threshold = 0.5\n",
        "predicted_masks = (predicted_masks > threshold).astype('uint8')\n",
        "print(predicted_masks.shape)\n",
        "for i in range(predicted_masks.shape[0]):\n",
        "         print(predicted_masks[i]*255)  \n",
        "\n",
        "         cv2.imwrite('ooo{}.png'.format(i), predicted_masks[i]*255)\n",
        "\n",
        "print('Done !')\n"
      ],
      "metadata": {
        "id": "KsBXT9S0ehTC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}